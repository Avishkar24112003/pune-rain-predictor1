# -*- coding: utf-8 -*-
"""Rain_Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/171jXtIeUVM9Vhu82KdXvBfPeFPaqQ_Dy
"""

# Basic data science libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Models
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.ensemble import RandomForestClassifier

# Preprocessing & evaluation
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, accuracy_score, classification_report, confusion_matrix

# Read your CSV file
data = pd.read_csv('/content/pune_city_data.csv')

# See first few rows to verify columns
print(data.head())

# OPTIONAL: Check column names if you need to match them exactly
print(data.columns)

# Assuming your target column is named 'rain' (0 = no rain, 1 = rain)
# Features: humidity, temperature, pressure
# Make sure these column names match your CSV exactly! If they are different, change them accordingly.
X = data[['humidity', 'temp', 'pressure']]
y = data['rain']

# Confirm shapes
print("Features shape:", X.shape)
print("Target shape:", y.shape)

# Basic statistics
print(data.describe())

# Drop the 'name' column as it's not numerical
data_numeric = data.drop('name', axis=1)

# Correlation heatmap
plt.figure(figsize=(8,6))
sns.heatmap(data_numeric.corr(), annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.show()

# Pairplot to visualize distributions
sns.pairplot(data_numeric, hue='rain' if 'rain' in data_numeric.columns else None)
plt.show()

# Assuming your target column is named 'rain'
X = data[['humidity', 'temp', 'pressure']]
y = data['rain']

# Split into train-test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

lr = LinearRegression()
lr.fit(X_train, y_train)
y_pred_lr = lr.predict(X_test)

# Evaluate
mse = mean_squared_error(y_test, y_pred_lr)
print(f'Linear Regression MSE: {mse:.4f}')

# Optional: Convert predictions to 0/1
# y_pred_lr_bin = (y_pred_lr >= 0.5).astype(int)
# print("LR Accuracy (thresholded):", accuracy_score(y_test, y_pred_lr_bin))

logr = LogisticRegression()
logr.fit(X_train, y_train)
y_pred_logr = logr.predict(X_test)

# Evaluate
print("Logistic Regression Accuracy:", accuracy_score(y_test, y_pred_logr))
print("Classification Report:\n", classification_report(y_test, y_pred_logr))

# Define a threshold for binary classification
# You might want to adjust this threshold based on your definition of 'rain'
rain_threshold = 0.5

# Create a new binary target variable
data['rain_binary'] = (data['rain'] > rain_threshold).astype(int)

# Display the first few rows with the new binary column
print(data[['rain', 'rain_binary']].head())

# Update X and y to use the new binary target
X = data[['humidity', 'temp', 'pressure']]
y = data['rain_binary']

# Split into train-test again with the new binary target
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y # Added stratify to maintain class distribution
)

print("\nUpdated Target shape:", y.shape)
print("Updated Training Target shape:", y_train.shape)
print("Updated Testing Target shape:", y_test.shape)

rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)

# Evaluate
print("Random Forest Accuracy:", accuracy_score(y_test, y_pred_rf))
print("Classification Report:\n", classification_report(y_test, y_pred_rf))

# Feature importance
importances = rf.feature_importances_
plt.barh(X.columns, importances)
plt.xlabel("Feature Importance")
plt.title("Random Forest Feature Importances")
plt.show()

# Predict on the test set with Logistic Regression
y_pred_logr = logr.predict(X_test)

# Convert 0/1 predictions to "Rain"/"Not Rain"
predicted_labels = ['Rain' if p == 1 else 'Not Rain' for p in y_pred_logr]

# Show first 20 predictions
print("üîπ Logistic Regression Predictions (as text):")
for i, label in enumerate(predicted_labels[:20]):
    print(f"Sample {i+1}: {label}")

# Predict on the test set with Random Forest
y_pred_rf = rf.predict(X_test)

# Convert to text labels
predicted_labels_rf = ['Rain' if p == 1 else 'Not Rain' for p in y_pred_rf]

print("\nüîπ Random Forest Predictions (as text):")
for i, label in enumerate(predicted_labels_rf[:20]):
    print(f"Sample {i+1}: {label}")

from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix

# Confusion matrix for Logistic Regression
cm = confusion_matrix(y_test, y_pred_logr)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Not Rain', 'Rain'])

plt.figure(figsize=(6,5))
disp.plot(cmap='Blues')
plt.title("Logistic Regression Confusion Matrix")
plt.show()

# Get user input
temp = float(input("Enter today's temperature (¬∞C): "))
humidity = float(input("Enter today's humidity (%): "))
pressure = float(input("Enter today's pressure (hPa): "))
# windspeed = float(input("Enter today's windspeed (km/h): ")) # Removed windspeed as it wasn't used in training

# Combine into a single new sample with the same features as training data
new_data = np.array([[humidity, temp, pressure]]) # Only include humidity, temp, pressure

# Predict with logistic regression
new_pred = logr.predict(new_data)

# Print result
result = "Rain" if new_pred[0] == 1 else "Not Rain"
print(f"\nüå¶Ô∏è Prediction for today ‚Üí {result}")

logr = LogisticRegression()
logr.fit(X_train, y_train)